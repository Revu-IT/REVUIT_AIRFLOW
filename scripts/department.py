import os
import pandas as pd
import numpy as np
import json, re
import time
from dotenv import load_dotenv
from openai import OpenAI
from langchain_openai import ChatOpenAI
#from langsmith import traceable

load_dotenv("/opt/airflow/.env", override=True)
AIRFLOW_HOME = "/opt/airflow"
DATA_FOLDER = os.path.join(AIRFLOW_HOME, "data")
DEPT_INFO_PATH = os.path.join(DATA_FOLDER, "department_info.csv")
COMPANY_NAME = os.getenv("COMPANY_NAME", "coupang").lower()
REVIEW_PATH = os.path.join(DATA_FOLDER, f"{COMPANY_NAME}_review_result.csv")

# LangChain LLM ê°ì²´ ìƒì„±
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.0
)

# ë¶€ì„œ ê¸°ì¤€ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
dept_df = pd.read_csv(DEPT_INFO_PATH, encoding="utf-8-sig")
dept_descriptions = ""
for _, row in dept_df.iterrows():
    dept_descriptions += f"{row['ì•„ì´ë””']}: {row['í†µí•© ë¶€ì„œëª…']}: {row['ì£¼ìš” í‚¤ì›Œë“œ']}\n"

#@traceable(name="review-dept-classification")
def ask_gpt_for_department(review_text):
    system_prompt = (
        "ë„ˆëŠ” ì‚¬ìš©ìì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ì„œ ì ì ˆí•œ ë¶€ì„œë¡œ ë¶„ë¥˜í•´ì£¼ëŠ” AIì•¼. ê°€ëŠ¥í•œ ë¶€ì„œëŠ” ì•„ë˜ì™€ ê°™ì•„:\n\n"
        + dept_descriptions +
        "\n\nì¡°ê±´:\n"
        "1. ë¶€ì„œ ì—¬ëŸ¬ ê°œë©´ ','ë¡œ ì •ìˆ˜ë§Œ ì•Œë ¤ì¤˜ (ì˜ˆ: 1,3)\n"
        #"2. confidence(1~10), think(ì´ìœ  í•œ ë¬¸ì¥) í¬í•¨\n"
        "2. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•´:\n"
        "{\n"
        "  \"department\": \"2,3\",\n"
        #"  \"confidence\": 8,\n"
        #"  \"think\": \"ë¦¬ë·°ì— ë°°ì†¡ê³¼ í’ˆì§ˆì— ëŒ€í•œ ë‚´ìš©ì´ ëª¨ë‘ ì–¸ê¸‰ë¨.\"\n"
        "}\n"
    )
    user_prompt = f"ë¦¬ë·°: \"{review_text}\""
    
    # LangChain LLM ì‚¬ìš©
    response = llm.invoke([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ])
    content = response.content.strip()
    
    try:
        json_str = re.search(r"\{.*\}", content, re.DOTALL).group()
        result = json.loads(json_str)
    except Exception as e:
        # result = {"department": "", "confidence": 0, "think": "ì˜¤ë¥˜ ë°œìƒ"}
        result = {"department": ""}
    
    # ë¶€ì„œ ì•„ì´ë””ë§Œ ì¶”ì¶œ
    dept_raw = result.get("department", "")
    dept_clean = ",".join([s.strip() for s in re.findall(r'\d+', dept_raw)])
    if not dept_clean:
        dept_clean = "0"
    return {
        "department": dept_clean,
        #"confidence": int(result.get("confidence", 0)),
        #"think": result.get("think", "")
    }

def classify_department():
    df = pd.read_csv(REVIEW_PATH, encoding="utf-8-sig")
    
    if "department" not in df.columns:
        df["department"] = np.nan

    updated = 0

    for i in range(len(df)):    
        if pd.isna(df.loc[i, "department"]) or str(df.loc[i, "department"]).strip() == "":
            result = ask_gpt_for_department(df.loc[i, "content"])
            df.at[i, "department"] = result["department"]
            updated += 1

            # ì¤‘ê°„ ì €ì¥ (50ê°œ ë‹¨ìœ„)
            if updated % 50 == 0:
                df.to_csv(REVIEW_PATH, index=False, encoding="utf-8-sig")
                print(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {updated}ê°œ ë¶„ë¥˜ ì™„ë£Œ")
                time.sleep(1)

    df.drop_duplicates(subset=["content", "date"], keep="last", inplace=True)
    df = df.sort_values(by="date", ascending=False)
    df.to_csv(REVIEW_PATH, index=False, encoding="utf-8-sig")
    print(f"âœ… ì „ì²´ ë¶€ì„œ ë¶„ë¥˜ ì™„ë£Œ: {updated}ê°œ ìƒˆë¡œ ë¶„ë¥˜ë¨ â†’ {REVIEW_PATH}")

# ì‚¬ìš© ì˜ˆì‹œ
classify_department()