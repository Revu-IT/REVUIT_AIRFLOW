import pandas as pd
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
import os

AIRFLOW_HOME = "/opt/airflow"
DATA_FOLDER = os.path.join(AIRFLOW_HOME, "data")
MODEL_FOLDER = os.path.join(AIRFLOW_HOME, "model")
INPUT_PATH = os.path.join(DATA_FOLDER, "G_review.csv")
OUTPUT_PATH = os.path.join(DATA_FOLDER, "G_review_bert.csv")
MODEL_PATH = os.path.join(MODEL_FOLDER, "bert")
TOKENIZER_PATH = os.path.abspath(os.path.join(MODEL_FOLDER, "tokenizer"))

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, local_files_only=True)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, local_files_only=True)

# Trainer ì„¤ì •
predict_args = TrainingArguments(
    output_dir=os.path.join(AIRFLOW_HOME, "predict_temp"),
    per_device_eval_batch_size=16,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=predict_args
)

df_all = pd.read_csv(INPUT_PATH, encoding='utf-8-sig')
df_all = df_all.dropna(subset=['content'])

# ê¸°ì¡´ ê°ì •ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(OUTPUT_PATH):
    df_prev = pd.read_csv(OUTPUT_PATH, encoding='utf-8-sig')
    print(f"[INFO] ì´ì „ ê°ì •ë¶„ì„ ë¦¬ë·° ìˆ˜: {len(df_prev)}")

    # ì´ë¯¸ ë¶„ì„ëœ ë¦¬ë·°ëŠ” ì œì™¸
    prev_contents = set(df_prev['content'])
    df_new = df_all[~df_all['content'].isin(prev_contents)]
    print(f"[INFO] ìƒˆë¡œ ë¶„ì„í•  ë¦¬ë·° ìˆ˜: {len(df_new)}")
else:
    df_prev = pd.DataFrame()
    df_new = df_all
    print("[INFO] ê¸°ì¡´ ê°ì •ë¶„ì„ ê²°ê³¼ ì—†ìŒ. ì „ì²´ ë¦¬ë·° ë¶„ì„")

# ìƒˆ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
if df_new.empty:
    print("ğŸš« ìƒˆë¡œ ë¶„ì„í•  ë¦¬ë·° ì—†ìŒ. ì¢…ë£Œ")
else:
    # í† í¬ë‚˜ì´ì§•
    texts = df_new['content'].astype(str).tolist()
    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)

    class UnlabeledDataset(torch.utils.data.Dataset):
        def __init__(self, encodings):
            self.encodings = encodings

        def __getitem__(self, idx):
            return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}

        def __len__(self):
            return len(self.encodings["input_ids"])

    dataset = UnlabeledDataset(encodings)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    output = trainer.predict(dataset)
    preds = np.argmax(output.predictions, axis=1)

    # ê²°ê³¼ ì¶”ê°€
    df_new['positive'] = preds  # 0: ë¶€ì •, 1: ê¸ì •

    # ê¸°ì¡´ ê²°ê³¼ì™€ í•©ì¹˜ê¸°
    df_final = pd.concat([df_prev, df_new], ignore_index=True)
    df_final.drop_duplicates(subset=['content'], inplace=True)

    df_final.to_csv(OUTPUT_PATH, index=False, encoding='utf-8-sig')
    print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ. ì´ ì €ì¥ ë¦¬ë·° ìˆ˜: {len(df_final)} â†’ {OUTPUT_PATH}")
