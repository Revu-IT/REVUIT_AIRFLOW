import os
import torch
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer


# âš ï¸ ê°ì ì´ì»¤ë¨¸ìŠ¤ëª…ìœ¼ë¡œ ë³€ê²½
AIRFLOW_HOME = "/opt/airflow"
DATA_FOLDER = os.path.join(AIRFLOW_HOME, "data")
MODEL_FOLDER = os.path.join(AIRFLOW_HOME, "model")
INPUT_PATH = os.path.join(DATA_FOLDER, "G_review_result.csv")
OUTPUT_PATH = os.path.join(DATA_FOLDER, "G_review_result.csv")
MODEL_PATH = os.path.join(MODEL_FOLDER, "bert")
TOKENIZER_PATH = os.path.abspath(os.path.join(MODEL_FOLDER, "tokenizer"))

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, local_files_only=True)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, local_files_only=True)

# Trainer ì„¤ì •
predict_args = TrainingArguments(
    output_dir=os.path.join(AIRFLOW_HOME, "predict_temp"),
    per_device_eval_batch_size=16,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=predict_args
)

df_all = pd.read_csv(INPUT_PATH, encoding='utf-8-sig')
df_all = df_all.dropna(subset=['content'])

# ê¸°ì¡´ ê°ì •ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
if 'positive' in df_all.columns:
    df_prev = df_all[df_all['positive'].notna()]
    print(f"âœ… ì´ì „ ê°ì •ë¶„ì„ ë¦¬ë·° ìˆ˜: {len(df_prev)}")

    # ì´ë¯¸ ë¶„ì„ëœ ë¦¬ë·°ëŠ” ì œì™¸
    df_new = df_all[df_all['positive'].isna()].copy()
    print(f"âœ… ìƒˆë¡œ ë¶„ì„í•  ë¦¬ë·° ìˆ˜: {len(df_new)}")
else:
    df_all['positive'] = np.nan
    df_prev = pd.DataFrame()
    df_new = df_all.copy()
    print("âœ… ê¸°ì¡´ ê°ì •ë¶„ì„ ì»¬ëŸ¼ ì—†ìŒ. ì „ì²´ ë¦¬ë·° ë¶„ì„")

# ìƒˆ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
if df_new.empty:
    print("ğŸš« ìƒˆë¡œ ë¶„ì„í•  ë¦¬ë·° ì—†ìŒ. ì¢…ë£Œ")
else:
    # í† í¬ë‚˜ì´ì§•
    texts = df_new['content'].astype(str).tolist()
    encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)

    class UnlabeledDataset(torch.utils.data.Dataset):
        def __init__(self, encodings):
            self.encodings = encodings

        def __getitem__(self, idx):
            return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}

        def __len__(self):
            return len(self.encodings["input_ids"])

    dataset = UnlabeledDataset(encodings)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    output = trainer.predict(dataset)
    preds = np.argmax(output.predictions, axis=1)

    # ê²°ê³¼ ì¶”ê°€
    df_new['positive'] = preds.astype(int)  # 0: ë¶€ì •, 1: ê¸ì •

    # ê¸°ì¡´ ê²°ê³¼ì™€ í•©ì¹˜ê¸°
    df_all = pd.concat([df_all, df_new], ignore_index=True)
    df_all.drop_duplicates(subset=["content", "date"], keep="last", inplace=True)
    df_all = df_all.sort_values(by="date", ascending=False)
    df_all.to_csv(OUTPUT_PATH, index=False, encoding="utf-8-sig")
    
    print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ. ì´ ì €ì¥ ë¦¬ë·° ìˆ˜: {len(df_all)} â†’ {OUTPUT_PATH}")
